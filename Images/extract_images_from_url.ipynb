{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# URL of the article you want to download images fro\n",
    "article_url = \"https://www.ebay.com/sch/i.html?_from=R40&_trksid=p2334524.m570.l1313&_nkw=laptop&_sacat=0&LH_TitleDesc=0&_osacat=0&_odkw=laptop\"\n",
    "\n",
    "# Parse the article\n",
    "article = Article(article_url)\n",
    "article.download()\n",
    "article.parse()\n",
    "\n",
    "# Create a directory to store images\n",
    "os.makedirs(\"article_images\", exist_ok=True)\n",
    "\n",
    "# Download and save each image in the article\n",
    "for i, img_url in enumerate(article.images):\n",
    "    try:\n",
    "        response = requests.get(img_url)\n",
    "        if response.status_code == 200:\n",
    "            # Check if the image format is supported and width is at least 500px\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            if img.format.lower() in [\"jpeg\", \"jpg\", \"png\"] and (img.width >= 200 or img.height >= 200):\n",
    "                with open(f\"article_images/image_{i}.{img.format.lower()}\", \"wb\") as img_file:\n",
    "                    img_file.write(response.content)\n",
    "                print(f\"Image {i} downloaded successfully.\")\n",
    "            else:\n",
    "                print(f\"Skipping image {i}: Unsupported format or width < 500px.\")\n",
    "        else:\n",
    "            print(f\"Error downloading image {i}: HTTP status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {i}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ChromeOptions\n",
    "\n",
    "\n",
    "def get_content_from_url(url):\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "    page_content = driver.page_source\n",
    "    driver.quit()\n",
    "    return page_content\n",
    "\n",
    "\n",
    "def parse_image_urls(content, classes, location, source):\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    results = []\n",
    "    for a in soup.findAll(attrs={\"class\": classes}):\n",
    "        name = a.find(location)\n",
    "        if name not in results:\n",
    "            results.append(name.get(source))\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_urls_to_csv(image_urls):\n",
    "    df = pd.DataFrame({\"links\": image_urls})\n",
    "    df.to_csv(\"links.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def get_and_save_image_to_file(image_url, output_dir):\n",
    "    image_content = requests.get(image_url).content\n",
    "    image_file = io.BytesIO(image_content)\n",
    "    image = Image.open(image_file).convert(\"RGB\")\n",
    "    filename = hashlib.sha1(image_content).hexdigest()[:10] + \".png\"\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    image.save(file_path, \"PNG\", quality=80)\n",
    "\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.ebay.com/sch/i.html?_from=R40&_trksid=p2334524.m570.l1313&_nkw=laptop&_sacat=0&LH_TitleDesc=0&_osacat=0&_odkw=laptop\"\n",
    "    content = get_content_from_url(url)\n",
    "    image_urls = parse_image_urls(\n",
    "        content=content, classes=\"s-item__image-wrapper image-treatment\", location=\"img\", source=\"src\"\n",
    "    )\n",
    "    save_urls_to_csv(image_urls)\n",
    "\n",
    "    for image_url in image_urls:\n",
    "        folder_path = \"article_images\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        get_and_save_image_to_file(\n",
    "            image_url, output_dir=Path(folder_path)\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
